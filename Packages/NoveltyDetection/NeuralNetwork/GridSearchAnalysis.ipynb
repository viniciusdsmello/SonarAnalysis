{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating /home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/NeuralNetwork/outputs/276498e1ea8f6cd0aee6dd08f8ddaae347d9913e0d27d5280df7829ac57bddeb\n",
      "Creating /home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/NeuralNetwork/outputs/276498e1ea8f6cd0aee6dd08f8ddaae347d9913e0d27d5280df7829ac57bddeb/AnalysisFiles\n",
      "Creating /home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/NeuralNetwork/outputs/276498e1ea8f6cd0aee6dd08f8ddaae347d9913e0d27d5280df7829ac57bddeb/Pictures\n",
      "Saving /home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/NeuralNetwork/outputs/276498e1ea8f6cd0aee6dd08f8ddaae347d9913e0d27d5280df7829ac57bddeb/parameters.json\n",
      "[+] Time to read data file: 1.102820634841919 seconds\n",
      "Qtd event of A is 12939\n",
      "Qtd event of B is 29352\n",
      "Qtd event of C is 11510\n",
      "Qtd event of D is 23760\n",
      "\n",
      "Biggest class is B with 29352 events\n",
      "Total of events in the dataset is 77561\n",
      "Balacing data...\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (12939, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (29352, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (11510, 400)\n",
      "DataHandler Class: CreateEventsForClass\n",
      "Original Size: (23760, 400)\n",
      "Reading from /home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/4_folds_cross_validation_balanced_data.jbl\n",
      "Reading from /home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/4_folds_cross_validation_balanced_data.jbl\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "import pprint \n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from Packages.NoveltyDetection.setup.noveltyDetectionConfig import CONFIG\n",
    "from NNNoveltyDetectionAnalysis import NNNoveltyDetectionAnalysis\n",
    "from Functions.telegrambot import Bot\n",
    "\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "my_bot = Bot(\"lisa_thebot\")\n",
    "\n",
    "# Enviroment variables\n",
    "data_path = CONFIG['OUTPUTDATAPATH']\n",
    "results_path = CONFIG['PACKAGE_NAME']\n",
    "\n",
    "training_params = {\n",
    "    \"Technique\": \"NeuralNetwork\",\n",
    "    \"DevelopmentMode\": False,\n",
    "    \"DevelopmentEvents\": 400,\n",
    "    \"NoveltyDetection\": True,\n",
    "    \"InputDataConfig\": {\n",
    "        \"database\": \"4classes\",\n",
    "        \"n_pts_fft\": 1024,\n",
    "        \"decimation_rate\": 3,\n",
    "        \"spectrum_bins_left\": 400,\n",
    "        \"n_windows\": 1,\n",
    "        \"balance_data\": True\n",
    "    },\n",
    "    \"OptmizerAlgorithm\": {\n",
    "        \"name\": \"Adam\",\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"beta_1\": 0.90,\n",
    "            \"beta_2\": 0.999,\n",
    "            \"epsilon\": 1e-08,\n",
    "            \"learning_decay\": 1e-6,\n",
    "            \"momentum\": 0.3,\n",
    "            \"nesterov\": True\n",
    "        }\n",
    "    },\n",
    "    \"HyperParameters\": {\n",
    "        \"n_folds\": 4,\n",
    "        \"n_epochs\": 300,\n",
    "        \"n_inits\": 2,\n",
    "        \"batch_size\": 256,\n",
    "        \"kernel_initializer\": \"uniform\",\n",
    "        \"hidden_activation_function\": \"tanh\", #\"relu\",\n",
    "        \"classifier_output_activation_function\": \"softmax\",\n",
    "        \"norm\": \"mapstd\",\n",
    "        \"metrics\": [\"accuracy\"],\n",
    "        \"loss\": \"mean_squared_error\",\n",
    "        \"dropout\": False,\n",
    "        \"dropout_parameter\": 0.0,\n",
    "        \"regularization\": None,\n",
    "        \"regularization_parameter\": 0.0\n",
    "    },\n",
    "    \"callbacks\": {\n",
    "        \"EarlyStopping\": {\n",
    "            \"patience\": 30,\n",
    "            \"monitor\": \"val_loss\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "analysis = NNNoveltyDetectionAnalysis(parameters=training_params, model_hash=\"\", load_hash=False, load_data=True, verbose=True)\n",
    "all_data, all_trgt, all_trgt_sparse = analysis.getData()\n",
    "\n",
    "trn_data = analysis.trn_data\n",
    "trn_trgt = analysis.trn_trgt\n",
    "trn_trgt_sparse = analysis.trn_trgt_sparse\n",
    "\n",
    "models = analysis.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de98c7f6f7697195e32a85b733b4c5b263d4419c5fb84c3dd3bb259eb106d88c\n",
      "/home/vinicius.mello/Workspace/SonarAnalysis/Results/NoveltyDetection/NeuralNetwork/outputs/de98c7f6f7697195e32a85b733b4c5b263d4419c5fb84c3dd3bb259eb106d88c\n",
      "{'DevelopmentEvents': 400,\n",
      " 'DevelopmentMode': True,\n",
      " 'HyperParameters': {'batch_size': 256,\n",
      "                     'classifier_output_activation_function': 'softmax',\n",
      "                     'dropout': False,\n",
      "                     'dropout_parameter': 0.0,\n",
      "                     'hidden_activation_function': 'tanh',\n",
      "                     'kernel_initializer': 'uniform',\n",
      "                     'loss': 'mean_squared_error',\n",
      "                     'metrics': ['accuracy'],\n",
      "                     'n_epochs': 200,\n",
      "                     'n_folds': 4,\n",
      "                     'n_inits': 2,\n",
      "                     'norm': 'mapstd',\n",
      "                     'regularization': None,\n",
      "                     'regularization_parameter': 0.0},\n",
      " 'InputDataConfig': {'balance_data': True,\n",
      "                     'database': '4classes',\n",
      "                     'decimation_rate': 3,\n",
      "                     'n_pts_fft': 1024,\n",
      "                     'n_windows': 1,\n",
      "                     'spectrum_bins_left': 400},\n",
      " 'NoveltyDetection': True,\n",
      " 'OptmizerAlgorithm': {'name': 'Adam',\n",
      "                       'parameters': {'beta_1': 0.9,\n",
      "                                      'beta_2': 0.999,\n",
      "                                      'epsilon': 1e-08,\n",
      "                                      'learning_decay': 1e-06,\n",
      "                                      'learning_rate': 0.001,\n",
      "                                      'momentum': 0.3,\n",
      "                                      'nesterov': True}},\n",
      " 'Technique': 'NeuralNetwork',\n",
      " 'callbacks': {'EarlyStopping': {'monitor': 'val_loss', 'patience': 30}}}\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "print(analysis.model_hash)\n",
    "print(analysis.getBaseResultsPath())\n",
    "pp.pprint(analysis.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "num_values = 10\n",
    "gridSearch = [copy.deepcopy(training_params) for i in range(num_values)]\n",
    "i = 10\n",
    "for params in gridSearch:\n",
    "    params['HyperParameters']['batch_size'] = 2**i\n",
    "    print (\"batch_size: {}\".format(params['HyperParameters']['batch_size']))\n",
    "    i = i - 1\n",
    "    for inovelty in range(len(analysis.class_labels)):\n",
    "        startTime = time.time()\n",
    "        analysis.setParameters(params)\n",
    "        analysis.train(layer=1,\n",
    "                       inovelty=inovelty,\n",
    "                       trainingType=\"neuronSweep\", #foldSweep, neuronSweep, normal\n",
    "                       hidden_neurons=[50],\n",
    "                       neurons_variation_step=5,\n",
    "                       numThreads=8,\n",
    "                       model_hash=analysis.model_hash, \n",
    "                       verbose=False)\n",
    "\n",
    "        duration = str(timedelta(seconds=float(time.time() - startTime)))\n",
    "        print \"The training of the model for novelty class {0} took {1} to be performed\\n\".format(analysis.class_labels[inovelty], duration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sp = 0\n",
    "best_param = None\n",
    "best_topology = None\n",
    "\n",
    "gridSearch_results = {}\n",
    "\n",
    "for inovelty in range(len(analysis.class_labels)):\n",
    "    print(\"Novelty Class: {}\".format(analysis.class_labels[inovelty]))\n",
    "    for ifold in range(analysis.n_folds):\n",
    "        print(\"Fold: {}\".format(ifold))\n",
    "        for iparams, params in enumerate(gridSearch):\n",
    "            analysis.setParameters(params)\n",
    "            train_id, test_id = analysis.CVO[inovelty][ifold]\n",
    "\n",
    "            # normalize known classes\n",
    "            if analysis.parameters[\"HyperParameters\"][\"norm\"] == \"mapstd\":\n",
    "                scaler = preprocessing.StandardScaler().fit(all_data[all_trgt!=inovelty][train_id,:])\n",
    "            elif analysis.parameters[\"HyperParameters\"][\"norm\"] == \"mapstd_rob\":\n",
    "                scaler = preprocessing.RobustScaler().fit(all_data[all_trgt!=inovelty][train_id,:])\n",
    "            elif analysis.parameters[\"HyperParameters\"][\"norm\"] == \"mapminmax\":\n",
    "                scaler = preprocessing.MinMaxScaler().fit(all_data[all_trgt!=inovelty][train_id,:])\n",
    "\n",
    "            known_data = scaler.transform(analysis.trn_data[inovelty][test_id,:])\n",
    "            known_target = analysis.trn_trgt[inovelty][test_id]\n",
    "            \n",
    "            #Import model\n",
    "            print(\"Loading model...\")\n",
    "            classifier = models[inovelty].get_model(data  = analysis.trn_data[inovelty],\n",
    "                                                    trgt  = analysis.trn_trgt[inovelty], \n",
    "                                                    hidden_neurons = hidden_neurons[:layer],\n",
    "                                                    layer = layer,\n",
    "                                                    ifold = ifold\n",
    "                                                   )\n",
    "\n",
    "            print(\"Classifier loaded with success.\")\n",
    "\n",
    "            #Get model output\n",
    "            output = classifier.predict(known_data)\n",
    "            #Get SP\n",
    "            sp_index_value = sp_index(known_target, np.argmax(output, axis=1))\n",
    "            gridSearch_results['topology{}'.format(iparams)]= {\n",
    "                'parameters': params, \n",
    "                'sp_index': sp_index_value\n",
    "            }\n",
    "            \n",
    "            if sp_index_value > best_sp:\n",
    "                best_sp = sp_index_value\n",
    "                best_param = params\n",
    "                best_topology = 'topology{}'.format(iparams)\n",
    "                \n",
    "print(\"Analysis has fished!\")\n",
    "my_bot.sendMessage(\"GridSearch Analysis has finished. Best topology was {}\".format(best_topology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose layer \n",
    "layer = 1\n",
    "\n",
    "# Choose neurons topology\n",
    "hidden_neurons = [50]\n",
    "\n",
    "step = 5\n",
    "neurons_mat = [1] + range(step,hidden_neurons[layer-1]+step,step)\n",
    "neurons_mat = neurons_mat[:len(neurons_mat)-layer+2]\n",
    "\n",
    "analysis_name = 'sp_index_%i_layer'%(layer)\n",
    "analysis_file = os.path.join(analysis.getBaseResultsPath(), \"AnalysisFiles\", analysis_name + \".jbl\")    \n",
    "\n",
    "verbose = True\n",
    "\n",
    "# Plot parameters\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['legend.numpoints'] = 1\n",
    "plt.rcParams['legend.handlelength'] = 3\n",
    "plt.rcParams['legend.borderpad'] = 0.3\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "m_colors = ['b', 'r', 'g', 'y']\n",
    "figsize = (10,5)\n",
    "\n",
    "\n",
    "results = {}\n",
    "spIndex = np.zeros([len(analysis.class_labels), analysis.parameters[\"HyperParameters\"][\"n_folds\"], len(neurons_mat)])\n",
    "\n",
    "if not os.path.exists(analysis_file):\n",
    "    for inovelty in range(len(analysis.class_labels)):\n",
    "        folds = range(len(analysis.CVO[inovelty]))\n",
    "        for ifold in folds:    \n",
    "            class_eff_mat = np.zeros([analysis.parameters[\"HyperParameters\"][\"n_folds\"],len(np.unique(all_trgt))])\n",
    "            known_sp_mat = np.zeros([analysis.parameters[\"HyperParameters\"][\"n_folds\"]])\n",
    "\n",
    "            buff = np.zeros([len(np.unique(all_trgt))-1])\n",
    "            class_eff = np.zeros([len(np.unique(all_trgt))], dtype=object)\n",
    "            known_sp = np.zeros([len(np.unique(all_trgt))], dtype=object)\n",
    "\n",
    "            def getSP(ineuron):\n",
    "                train_id, test_id = analysis.CVO[inovelty][ifold]\n",
    "\n",
    "                # normalize known classes\n",
    "                if analysis.parameters[\"HyperParameters\"][\"norm\"] == \"mapstd\":\n",
    "                    scaler = preprocessing.StandardScaler().fit(all_data[all_trgt!=inovelty][train_id,:])\n",
    "                elif analysis.parameters[\"HyperParameters\"][\"norm\"] == \"mapstd_rob\":\n",
    "                    scaler = preprocessing.RobustScaler().fit(all_data[all_trgt!=inovelty][train_id,:])\n",
    "                elif analysis.parameters[\"HyperParameters\"][\"norm\"] == \"mapminmax\":\n",
    "                    scaler = preprocessing.MinMaxScaler().fit(all_data[all_trgt!=inovelty][train_id,:])\n",
    "\n",
    "                known_data = scaler.transform(analysis.trn_data[inovelty][test_id,:])\n",
    "                known_trgt = analysis.trn_trgt[inovelty][test_id]\n",
    "                classifier = models[inovelty].get_model(data  = analysis.trn_data[inovelty],\n",
    "                                                        trgt  = analysis.trn_trgt[inovelty], \n",
    "                                                        hidden_neurons = hidden_neurons[:layer-1]+[ineuron],\n",
    "                                                        layer = layer,\n",
    "                                                        ifold = ifold\n",
    "                                                       )\n",
    "\n",
    "                output = classifier.predict(known_data)\n",
    "\n",
    "                num_known_classes = analysis.trn_trgt_sparse[inovelty].shape[1]\n",
    "                thr_value = 0.2\n",
    "                for iclass, class_id in enumerate(np.unique(all_trgt)):\n",
    "                    if iclass == inovelty:\n",
    "                        continue\n",
    "                    output_of_class_events = output[known_trgt==iclass-(iclass>inovelty),:]\n",
    "                    correct_class_output = np.argmax(output_of_class_events,axis=1)==iclass-(iclass>inovelty)\n",
    "                    output_above_thr = output_of_class_events[correct_class_output,iclass-(iclass>inovelty)]>thr_value\n",
    "                    class_eff = float(sum(output_above_thr))/float(len(output_of_class_events))\n",
    "                    buff[iclass-(iclass>inovelty)] = class_eff\n",
    "\n",
    "                sp_index = (np.sqrt(np.mean(buff,axis=0)*np.power(np.prod(buff),1./float(len(buff)))))\n",
    "                \n",
    "                return ineuron, sp_index\n",
    "\n",
    "            # Start Parallel processing\n",
    "            p = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "            if verbose:\n",
    "                print '[*] Calculating SP Index ...'\n",
    "            results = p.map(getSP, neurons_mat)\n",
    "\n",
    "            for ineuron_index in range(len(neurons_mat)):\n",
    "                spIndex[inovelty, ifold, neurons_mat.index(results[ineuron_index][0])] = results[ineuron_index][1]\n",
    "\n",
    "            p.close()\n",
    "            p.join()\n",
    "\n",
    "    joblib.dump([neurons_mat,spIndex],analysis_file,compress=9)\n",
    "else:\n",
    "    [neurons_mat, spIndex] = joblib.load(analysis_file)\n",
    "\n",
    "    \n",
    "for inovelty in range(len(analysis.class_labels)):\n",
    "    # Plot results    \n",
    "    fig = plt.subplots(figsize=figsize)\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    mean_sp = np.mean(spIndex[inovelty,:], axis=0)\n",
    "    error_sp = np.std(spIndex[inovelty,:,:], axis=0)\n",
    "    \n",
    "    ax.plot(neurons_mat, mean_sp, color='b', alpha=0.7, linewidth=2.5, label='SP Index Test Data')\n",
    "    \n",
    "    ax.fill_between(neurons_mat, mean_sp+error_sp, mean_sp-error_sp, facecolor='blue', alpha=0.3)\n",
    "    \n",
    "    ax.set_title('SP Index x Neurons (Class {} as novelty)'.format(analysis.class_labels[inovelty]),\n",
    "                                  fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('SP Index', fontsize=22)\n",
    "    ax.set_xlabel('Neurons', fontsize=22)\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    #Save the figure\n",
    "    neurons_str = models[inovelty].get_neurons_str(trn_data[inovelty],hidden_neurons=hidden_neurons)\n",
    "    file_name = os.path.join(analysis.pictures_output_folder, analysis_name+\"_{}_novelty_{}_neurons.png\".format(inovelty,neurons_str))\n",
    "    plt.savefig(file_name, format=\"png\")\n",
    "    try: \n",
    "        my_bot.sendMessage(imgPath=file_name)\n",
    "    except Exception as e:\n",
    "        print(\"Error when sending the image to the bot. Error: {}\".format(str(e)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
